---
title: Hugging Face
---

All LangChain integrations with [Hugging Face Hub](https://huggingface.co/) and libraries like [transformers](https://huggingface.co/docs/transformers/index), [sentence transformers](https://sbert.net/), and [datasets](https://huggingface.co/docs/datasets/index).

{/* ## Installation and setup

<CodeGroup>
    ```bash pip
    pip install langchain-huggingface
    ```

    ```bash uv
    uv add langchain-huggingface
    ```
</CodeGroup> */}

## Chat models

### ChatHuggingFace

We can use the `Hugging Face` LLM classes or directly use the `ChatHuggingFace` class.

See a [usage example](/oss/python/integrations/chat/huggingface).

```python
from langchain_huggingface import ChatHuggingFace
```

## LLMs

### HuggingFaceEndpoint

We can use the `HuggingFaceEndpoint` class to run open source models via serverless [Inference Providers](https://huggingface.co/docs/inference-providers) or via dedicated [Inference Endpoints](https://huggingface.co/inference-endpoints/dedicated).

See a [usage example](/oss/python/integrations/llms/huggingface_endpoint).

```python
from langchain_huggingface import HuggingFaceEndpoint
```

### HuggingFacePipeline

We can use the `HuggingFacePipeline` class to run open source models locally.

See a [usage example](/oss/python/integrations/llms/huggingface_pipelines).

```python
from langchain_huggingface import HuggingFacePipeline
```

## Embedding Models

### HuggingFaceEmbeddings

We can use the `HuggingFaceEmbeddings` class to run open source embedding models locally.

See a [usage example](/oss/python/integrations/text_embedding/huggingfacehub).

```python
from langchain_huggingface import HuggingFaceEmbeddings
```

### HuggingFaceEndpointEmbeddings

We can use the `HuggingFaceEndpointEmbeddings` class to run open source embedding models via a dedicated [Inference Endpoint](https://huggingface.co/inference-endpoints/dedicated).

See a [usage example](/oss/python/integrations/text_embedding/huggingfacehub).

```python
from langchain_huggingface import HuggingFaceEndpointEmbeddings
```

### HuggingFaceInferenceAPIEmbeddings

We can use the `HuggingFaceInferenceAPIEmbeddings` class to run open source embedding models via [Inference Providers](https://huggingface.co/docs/inference-providers).

See a [usage example](/oss/python/integrations/text_embedding/huggingfacehub).

```python
from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings
```

### HuggingFaceInstructEmbeddings

We can use the `HuggingFaceInstructEmbeddings` class to run open source embedding models locally.

See a [usage example](/oss/python/integrations/text_embedding/instruct_embeddings).

```python
from langchain_community.embeddings import HuggingFaceInstructEmbeddings
```

### HuggingFaceBgeEmbeddings

>[BGE models on the HuggingFace](https://huggingface.co/BAAI/bge-large-en-v1.5) are one of [the best open-source embedding models](https://huggingface.co/spaces/mteb/leaderboard).
>BGE model is created by the [Beijing Academy of Artificial Intelligence (BAAI)](https://en.wikipedia.org/wiki/Beijing_Academy_of_Artificial_Intelligence). `BAAI` is a private non-profit organization engaged in AI research and development.

See a [usage example](/oss/python/integrations/text_embedding/bge_huggingface).

```python
from langchain_community.embeddings import HuggingFaceBgeEmbeddings
```

## Document loaders

### Hugging Face dataset

>[Hugging Face Hub](https://huggingface.co/docs/hub/index) is home to over 75,000
> [datasets](https://huggingface.co/docs/hub/index#datasets) in more than 100 languages
> that can be used for a broad range of tasks across NLP, Computer Vision, and Audio.
> They used for a diverse range of tasks such as translation, automatic speech
> recognition, and image classification.

We need to install `datasets` python package.

<CodeGroup>
    ```bash pip
    pip install datasets
    ```

    ```bash uv
    uv add datasets
    ```
</CodeGroup>

See a [usage example](/oss/python/integrations/document_loaders/hugging_face_dataset).

```python
from langchain_community.document_loaders.hugging_face_dataset import HuggingFaceDatasetLoader
```

### Hugging Face model loader

>Load model information from `Hugging Face Hub`, including README content.
>
>This loader interfaces with the `Hugging Face Models API` to fetch
> and load model metadata and README files.
> The API allows you to search and filter models based on
> specific criteria such as model tags, authors, and more.

```python
from langchain_community.document_loaders import HuggingFaceModelLoader
```

### Image captions

It uses the Hugging Face models to generate image captions.

We need to install several python packages.

<CodeGroup>
    ```bash pip
    pip install transformers pillow
    ```

    ```bash uv
    uv add transformers pillow
    ```
</CodeGroup>

See a [usage example](/oss/python/integrations/document_loaders/image_captions).

```python
from langchain_community.document_loaders import ImageCaptionLoader
```

## Tools

### Hugging Face Hub Tools

>[Hugging Face Tools](https://huggingface.co/docs/transformers/v4.29.0/en/custom_tools)
> support text I/O and are loaded using the `load_huggingface_tool` function.

We need to install several python packages.

<CodeGroup>
    ```bash pip
    pip install transformers huggingface_hub
    ```

    ```bash uv
    uv add transformers huggingface_hub
    ```
</CodeGroup>

See a [usage example](/oss/python/integrations/tools/huggingface_tools).

```python
from langchain_community.agent_toolkits.load_tools import load_huggingface_tool
```

### Hugging Face Text-to-Speech Model Inference.

> It is a wrapper around `OpenAI Text-to-Speech API`.

```python
from langchain_community.tools.audio import HuggingFaceTextToSpeechModelInference
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/providers/huggingface.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
